{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Zoomcamp 2025: Homework 1\n",
    "\n",
    "This notebook solves the homework for predicting NYC Yellow Taxi trip durations using January and February 2023 data. We train a LinearRegression model with one-hot encoded pickup and dropoff location IDs and evaluate it on training and validation sets.\n",
    "\n",
    "## Questions\n",
    "1. How many columns in the January 2023 dataset?\n",
    "2. What’s the standard deviation of trip durations in January?\n",
    "3. What fraction of records remain after removing duration outliers (1–60 minutes)?\n",
    "4. What’s the dimensionality of the feature matrix after one-hot encoding?\n",
    "5. What’s the RMSE on the training data?\n",
    "6. What’s the RMSE on the validation data (February 2023)?\n",
    "\n",
    "## Environment\n",
    "- Run in `exp-tracking-env` conda environment.\n",
    "- Dependencies: pandas, scikit-learn, mlflow, pyarrow, requests.\n",
    "- MLflow tracking URI: `sqlite:///mlflow.db`, Experiment: `nyc-taxi-homework`.\n",
    "- Data: Yellow Taxi Trip Records from [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "Import libraries and configure MLflow tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "import logging\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Set MLflow tracking\n",
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "mlflow.set_experiment('nyc-taxi-homework')\n",
    "\n",
    "# Ensure data and models directories exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Downloading and Loading Data\n",
    "\n",
    "Download Yellow Taxi Trip Records for January and February 2023 from the TLC website and load the January data to count columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 01:56:53,040 - INFO - Downloading data/yellow_tripdata_2023-01.parquet\n",
      "2025-05-21 01:57:02,186 - INFO - Successfully downloaded data/yellow_tripdata_2023-01.parquet (47673370 bytes)\n",
      "2025-05-21 01:57:02,187 - INFO - Downloading data/yellow_tripdata_2023-02.parquet\n",
      "2025-05-21 01:57:11,850 - INFO - Successfully downloaded data/yellow_tripdata_2023-02.parquet (47748012 bytes)\n",
      "2025-05-21 01:57:12,189 - INFO - Number of columns in January 2023 data: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 Answer: 19\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "urls = {\n",
    "    '01': 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet',\n",
    "    '02': 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet'\n",
    "}\n",
    "\n",
    "for month, url in urls.items():\n",
    "    filename = f'data/yellow_tripdata_2023-{month}.parquet'\n",
    "    if not os.path.exists(filename) or os.path.getsize(filename) == 0:\n",
    "        try:\n",
    "            logging.info(f'Downloading {filename}')\n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            if os.path.getsize(filename) > 0:\n",
    "                logging.info(f'Successfully downloaded {filename} ({os.path.getsize(filename)} bytes)')\n",
    "            else:\n",
    "                logging.error(f'Downloaded file {filename} is empty')\n",
    "                raise ValueError(f'Empty file downloaded for {filename}')\n",
    "        except (requests.exceptions.RequestException, ValueError) as e:\n",
    "            logging.error(f'Failed to download {filename}: {e}')\n",
    "            raise\n",
    "    else:\n",
    "        logging.info(f'{filename} already exists and is non-empty ({os.path.getsize(filename)} bytes)')\n",
    "\n",
    "# Load January data\n",
    "try:\n",
    "    df_jan = pd.read_parquet('data/yellow_tripdata_2023-01.parquet')\n",
    "    num_columns = len(df_jan.columns)\n",
    "    logging.info(f'Number of columns in January 2023 data: {num_columns}')\n",
    "    print(f'Q1 Answer: {num_columns}')\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f'File not found: {e}')\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logging.error(f'Error loading January data: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 & Q3: Computing Duration and Dropping Outliers\n",
    "\n",
    "Compute trip duration in minutes, calculate its standard deviation, and filter out durations outside 1–60 minutes to find the fraction of remaining records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 01:57:12,520 - INFO - Loaded data/yellow_tripdata_2023-01.parquet with 3066766 rows\n",
      "2025-05-21 01:57:12,580 - INFO - Standard deviation of duration: 42.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 Answer: 42.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 01:57:12,960 - INFO - Fraction of records remaining: 98.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 Answer: 98%\n"
     ]
    }
   ],
   "source": [
    "def read_dataframe(filename):\n",
    "    try:\n",
    "        df = pd.read_parquet(filename)\n",
    "        df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "        logging.info(f'Loaded {filename} with {len(df)} rows')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error reading {filename}: {e}')\n",
    "        raise\n",
    "\n",
    "# Load and preprocess January data\n",
    "df_jan = read_dataframe('data/yellow_tripdata_2023-01.parquet')\n",
    "\n",
    "# Q2: Standard deviation of duration\n",
    "std_duration = df_jan['duration'].std()\n",
    "logging.info(f'Standard deviation of duration: {std_duration:.2f}')\n",
    "print(f'Q2 Answer: {std_duration:.2f}')\n",
    "\n",
    "# Q3: Fraction of records after removing outliers\n",
    "original_count = len(df_jan)\n",
    "df_jan_filtered = df_jan[(df_jan['duration'] >= 1) & (df_jan['duration'] <= 60)]\n",
    "filtered_count = len(df_jan_filtered)\n",
    "fraction_remaining = filtered_count / original_count\n",
    "logging.info(f'Fraction of records remaining: {fraction_remaining:.2%}')\n",
    "print(f'Q3 Answer: {fraction_remaining:.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: One-hot Encoding\n",
    "\n",
    "Apply one-hot encoding to pickup and dropoff location IDs and get the dimensionality of the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/9f3zz4n125vcqtdw9lx47mjw0000gn/T/ipykernel_26747/669157849.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['161' '43' '48' ... '114' '230' '262']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_jan_filtered.loc[:, 'PULocationID'] = df_jan_filtered['PULocationID'].astype(str)\n",
      "/var/folders/6n/9f3zz4n125vcqtdw9lx47mjw0000gn/T/ipykernel_26747/669157849.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['141' '237' '238' ... '239' '79' '143']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_jan_filtered.loc[:, 'DOLocationID'] = df_jan_filtered['DOLocationID'].astype(str)\n",
      "2025-05-21 01:57:26,183 - INFO - Dimensionality of feature matrix: 515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 Answer: 515\n"
     ]
    }
   ],
   "source": [
    "# Prepare features\n",
    "df_jan_filtered.loc[:, 'PULocationID'] = df_jan_filtered['PULocationID'].astype(str)\n",
    "df_jan_filtered.loc[:, 'DOLocationID'] = df_jan_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_jan_filtered[categorical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "logging.info(f'Dimensionality of feature matrix: {num_features}')\n",
    "print(f'Q4 Answer: {num_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Training a Model\n",
    "\n",
    "Train a LinearRegression model on the January data and compute RMSE on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 01:58:02,182 - INFO - Training RMSE: 7.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 Answer: 7.65\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.set_tag('model', 'LinearRegression')\n",
    "    mlflow.set_tag('developer', 'John')\n",
    "    mlflow.log_param('train-data-path', './data/yellow_tripdata_2023-01.parquet')\n",
    "    mlflow.log_param('features', 'PULocationID, DOLocationID')\n",
    "\n",
    "    y_train = df_jan_filtered['duration'].values\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_train)\n",
    "    rmse_train = root_mean_squared_error(y_train, y_pred)\n",
    "    mlflow.log_metric('rmse_train', rmse_train)\n",
    "\n",
    "    with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "        pickle.dump((dv, lr), f_out)\n",
    "    mlflow.log_artifact('models/lin_reg.bin', artifact_path='models_pickle')\n",
    "\n",
    "    input_example = X_train[:5].toarray()\n",
    "    signature = infer_signature(X_train, y_pred)\n",
    "    mlflow.sklearn.log_model(lr, artifact_path='models_mlflow', signature=signature, input_example=input_example)\n",
    "\n",
    "    logging.info(f'Training RMSE: {rmse_train:.2f}')\n",
    "    print(f'Q5 Answer: {rmse_train:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Evaluating the Model\n",
    "\n",
    "Apply the trained model to February 2023 data and compute RMSE on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 01:58:02,528 - INFO - Loaded data/yellow_tripdata_2023-02.parquet with 2913955 rows\n",
      "2025-05-21 01:58:07,828 - INFO - Validation RMSE: 13.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6 Answer: 13.32\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess February data\n",
    "df_feb = read_dataframe('data/yellow_tripdata_2023-02.parquet')\n",
    "df_feb_filtered = df_feb[(df_feb['duration'] >= 1) & (df_feb['duration'] <= 60)]\n",
    "\n",
    "# Prepare validation features\n",
    "val_dicts = df_feb_filtered[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "y_val = df_feb_filtered['duration'].values\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag('model', 'LinearRegression')\n",
    "    mlflow.set_tag('developer', 'John')\n",
    "    mlflow.log_param('valid-data-path', './data/yellow_tripdata_2023-02.parquet')\n",
    "    mlflow.log_param('features', 'PULocationID, DOLocationID')\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse_val = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric('rmse_val', rmse_val)\n",
    "\n",
    "    logging.info(f'Validation RMSE: {rmse_val:.2f}')\n",
    "    print(f'Q6 Answer: {rmse_val:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
